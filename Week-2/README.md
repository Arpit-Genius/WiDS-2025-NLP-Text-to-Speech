# WEEK 2 - Deep Learning for NLP

## Learning Outcomes

### Concepts

- Learned the concept of **word embeddings** and how words are represented as dense vectors.
- Studied popular embedding techniques - **Word2Vec**.
- Understood the role of **neural networks in NLP**.
- Learned the working principles of **Recurrent Neural Networks (RNN)**, **GRU**, and **LSTM**.
- Gained an overview of the **attention mechanism** and its importance in sequence modeling.


### Coding Tasks

- Trained **Word2Vec** on a small text corpus.
- Implemented an **LSTM-based sentiment classification model**.
- Visualized learned word embeddings using **t-SNE** for dimensionality reduction.

### Mini-Project

Compared and analysed the below approaches on a given dataset:
  - **TF-IDF + Logistic Regression**
  - **LSTM-based classifier**
